{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#11.Implement a simple top-down parser for context-free grammars using python.#\n"
      ],
      "metadata": {
        "id": "wKeBsj7kRhTV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SimpleParser:\n",
        "    def __init__ (self, grammar):\n",
        "        self.grammar = grammar\n",
        "    def parse (self, input_string):\n",
        "        self.input = input_string\n",
        "        self.index = 0\n",
        "        self.result = True\n",
        "        if self.expression ():\n",
        "            if self.index == len (self.input):\n",
        "                print (f'Parsing successful for input: {input_string}')\n",
        "                return\n",
        "        print (f'Parsing failed for input: {input_string}')\n",
        "    def expression (self):\n",
        "        return self.term () and self.expression_tail ()\n",
        "    def expression_tail (self):\n",
        "        current_index = self.index\n",
        "        if self.match ('+'):\n",
        "            return self.term () and self.expression_tail ()\n",
        "        self.index = current_index\n",
        "        return True\n",
        "    def term (self):\n",
        "        return self.factor () and self.term_tail ()\n",
        "    def term_tail (self):\n",
        "        current_index = self.index\n",
        "        if self.match ('*'):\n",
        "            return self.factor () and self.term_tail ()\n",
        "        self.index = current_index\n",
        "        return True\n",
        "    def factor (self):\n",
        "        if self.match ('('):\n",
        "            if self.expression () and self.match (')'):\n",
        "                return True\n",
        "            return False\n",
        "        return self.match ('number')\n",
        "    def match (self, expected):\n",
        "        if self.index < len (self.input) and (expected == self.input [self.index] or expected == 'number' and self.input [self.index].isdigit ()):\n",
        "            self.index += 1\n",
        "            return True\n",
        "        return False\n",
        "\n",
        "grammar = {\n",
        "    'start': 'Expression',\n",
        "}\n",
        "\n",
        "parser = SimpleParser (grammar)\n",
        "\n",
        "parser.parse ('3* (2+1)')\n",
        "parser.parse ('2+1*3')\n",
        "parser.parse ('2+ (1*1)')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9hSypzHhL9MU",
        "outputId": "6675dc51-9a48-42cb-91e1-e8cbd693872c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Parsing failed for input: 3* (2+1)\n",
            "Parsing successful for input: 2+1*3\n",
            "Parsing failed for input: 2+ (1*1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#12. Implement an Earley parser for context-free grammars using a simple python program.#\n"
      ],
      "metadata": {
        "id": "B3NSBeTpjlP3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "jGXTCfCcko7U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class EarleyParser:\n",
        "    def __init__(self, grammar):\n",
        "        self.grammar = grammar\n",
        "    def parse(self, input_string):\n",
        "        self.chart = [[] for _ in range(len(input_string) + 1)]\n",
        "        self.chart[0].append(('start', '', 0))\n",
        "        for i in range(len(input_string) + 1):\n",
        "            for state in self.chart[i]:\n",
        "                self.predictor(state, i)\n",
        "                if i < len(input_string):\n",
        "                    self.scanner(state, input_string[i], i)\n",
        "                else:\n",
        "                    self.completer(state, i)\n",
        "        if ('start', self.grammar['start'], 0) in self.chart[len(input_string)]:\n",
        "            print(f'Parsing failed for input: {input_string}')\n",
        "        else:\n",
        "            print(f'Parsing successfull for input: {input_string}')\n",
        "    def predictor(self, state, index):\n",
        "        if state[1] in self.grammar:\n",
        "            for production in self.grammar[state[1]]:\n",
        "                self.chart[index].append((state[1], production, index))\n",
        "    def scanner(self, state, token, index):\n",
        "        if state[1] == '' or state[1][0] != token:\n",
        "            return\n",
        "        self.chart[index + 1].append((state[0], state[1][1:], state[2]))\n",
        "    def completer(self, state, index):\n",
        "        for st in self.chart[state[2]]:\n",
        "            if st[1] == '' or st[1][0] != state[0]:\n",
        "                continue\n",
        "            self.chart[index].append((st[0], st[1][1:], st[2]))\n",
        "# Example usage\n",
        "grammar = {\n",
        "    'start': 'Expression',\n",
        "    'Expression': ['Term + Expression', 'Term'],\n",
        "    'Term': ['Factor * Term', 'Factor'],\n",
        "    'Factor': ['( Expression )', 'number']\n",
        "}\n",
        "\n",
        "parser = EarleyParser(grammar)\n",
        "\n",
        "# Test the parser\n",
        "parser.parse('3* (2+1)') # Parsing successful for input: 3* (2+1)\n",
        "parser.parse('2+1*3') # Parsing successful for input: 2+1*3\n",
        "parser.parse('2+ (1*3)') # Parsing successful for input: 2+ (1*3)\n"
      ],
      "metadata": {
        "id": "HA9oegu_SFM_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "300c0391-16ab-421d-8aeb-50758b107711"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Parsing successfull for input: 3* (2+1)\n",
            "Parsing successfull for input: 2+1*3\n",
            "Parsing successfull for input: 2+ (1*3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#13. Generate a parse tree for a given sentence using a context-free grammar using python program.#"
      ],
      "metadata": {
        "id": "FpiTdWdxLxpP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "def generate_parse_tree(sentence, grammar):\n",
        "    tokens = nltk.word_tokenize(sentence)\n",
        "    parser = nltk.ChartParser(grammar)\n",
        "    parse_tree = None\n",
        "    for tree in parser.parse(tokens):\n",
        "        parse_tree = tree\n",
        "        break\n",
        "    return parse_tree\n",
        "example_grammar = nltk.CFG.fromstring(\"\"\"\n",
        "    S -> NP VP\n",
        "    NP -> Det N\n",
        "    VP -> V NP\n",
        "    Det -> 'the' | 'a'\n",
        "    N -> 'cat' | 'dog'\n",
        "    V -> 'chased' | 'caught'\n",
        "\"\"\")\n",
        "example_sentence = \"the cat chased a dog\"\n",
        "parse_tree = generate_parse_tree(example_sentence, example_grammar)\n",
        "if parse_tree:\n",
        "    parse_tree.pretty_print()\n",
        "else:\n",
        "    print(\"No parse tree found for the given sentence.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GOKSZfFgLnBz",
        "outputId": "5e71641b-e65c-4555-db82-62b562ee84ee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              S               \n",
            "      ________|_____           \n",
            "     |              VP        \n",
            "     |         _____|___       \n",
            "     NP       |         NP    \n",
            "  ___|___     |      ___|___   \n",
            "Det      N    V    Det      N \n",
            " |       |    |     |       |  \n",
            "the     cat chased  a      dog\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 14.Create a program in python to check for agreement in sentences based on a context-free grammar's rules.#\n"
      ],
      "metadata": {
        "id": "fdarY5FRLQqQ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MDsay6JSH10V",
        "outputId": "8c4ee28b-818e-4eea-c15f-759910530f0e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Subject-verb agreement error:\n",
            "Subjects: ['cat', 'dog'] (singular)\n",
            "Verbs: ['catches'] (plural)\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "def check_agreement(sentence):\n",
        "    tagged_words = nltk.pos_tag(nltk.word_tokenize(sentence))\n",
        "    subjects = [word for word, tag in tagged_words if tag.startswith('N')]\n",
        "    verbs = [word for word, tag in tagged_words if tag.startswith('V')]\n",
        "    if subjects and verbs:\n",
        "        subject_number = 'singular' if tagged_words[0][1].startswith('NNS') else 'singular'\n",
        "        verb_number = 'singular' if tagged_words[-1][1].startswith('VB') else 'plural'\n",
        "        if subject_number != verb_number:\n",
        "            print(\"Subject-verb agreement error:\")\n",
        "            print(f\"Subjects: {subjects} ({subject_number})\")\n",
        "            print(f\"Verbs: {verbs} ({verb_number})\")\n",
        "        else:\n",
        "            print(\"Subject-verb agreement is correct.\")\n",
        "    else:\n",
        "        print(\"Unable to find subjects and verbs in the sentence.\")\n",
        "example_sentence = \"The cat catches a dog\"\n",
        "check_agreement(example_sentence)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 15.Implement a simple top-down parser for context-free grammars using python.#\n"
      ],
      "metadata": {
        "id": "t-ln7ybaMXSZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "\n",
        "nltk.download('punkt')\n",
        "\n",
        "def pcfg_parse(sentence, pcfg_grammar):\n",
        "    tokens = nltk.word_tokenize(sentence)\n",
        "    parser = nltk.EarleyChartParser(pcfg_grammar)\n",
        "    parse_tree = None\n",
        "    for tree in parser.parse(tokens):\n",
        "        parse_tree = tree\n",
        "        break\n",
        "    return parse_tree\n",
        "pcfg_grammar = nltk.PCFG.fromstring(\"\"\"\n",
        "    S -> NP VP [1.0]\n",
        "    NP -> Det N [0.5] | N [0.5]\n",
        "    VP -> V NP [0.7] | VP PP [0.3]\n",
        "    PP -> P NP [1.0]\n",
        "    Det -> 'the' [0.8] | 'a' [0.2]\n",
        "    N -> 'cat' [0.4] | 'dog' [0.6]\n",
        "    V -> 'chased' [0.9] | 'caught' [0.1]\n",
        "    P -> 'in' [0.6] | 'on' [0.4]\n",
        "\"\"\")\n",
        "example_sentence = \"the cat chased a dog\"\n",
        "parse_tree = pcfg_parse(example_sentence, pcfg_grammar)\n",
        "if parse_tree:\n",
        "    parse_tree.pretty_print()\n",
        "else:\n",
        "    print(\"No parse tree found for the given sentence.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bZm6rJr3MD_O",
        "outputId": "e79f0578-6e17-4cf1-fcb8-6fca74d8efc2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              S               \n",
            "      ________|_____           \n",
            "     |              VP        \n",
            "     |         _____|___       \n",
            "     NP       |         NP    \n",
            "  ___|___     |      ___|___   \n",
            "Det      N    V    Det      N \n",
            " |       |    |     |       |  \n",
            "the     cat chased  a      dog\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 16 Implement a Python program using the SpaCy library to perform Named Entity Recognition (NER) on a given text.#"
      ],
      "metadata": {
        "id": "78bfsgaOM_f5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "def perform_ner(text):\n",
        "    nlp = spacy.load(\"en_core_web_sm\")\n",
        "    doc = nlp(text)\n",
        "    entities = [(ent.text, ent.label_) for ent in doc.ents]\n",
        "    return entities\n",
        "example_text = \"Apple Inc. was founded by Steve Jobs in Cupertino. The iPhone was first released in 2007.\"\n",
        "ner_results = perform_ner(example_text)\n",
        "for entity, label in ner_results:\n",
        "    print(f\"{entity} - {label}\")\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ObOHVlSyMD76",
        "outputId": "0fa47c37-0ab2-4f4f-a9b4-0b10b91b97bb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Apple Inc. - ORG\n",
            "Steve Jobs - PERSON\n",
            "Cupertino - GPE\n",
            "iPhone - ORG\n",
            "first - ORDINAL\n",
            "2007 - DATE\n"
          ]
        }
      ]
    }
  ]
}